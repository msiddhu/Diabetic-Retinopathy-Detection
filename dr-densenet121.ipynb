{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d48492",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-20T12:16:16.507404Z",
     "iopub.status.busy": "2022-04-20T12:16:16.506773Z",
     "iopub.status.idle": "2022-04-20T12:16:21.231354Z",
     "shell.execute_reply": "2022-04-20T12:16:21.230605Z"
    },
    "papermill": {
     "duration": 4.740881,
     "end_time": "2022-04-20T12:16:21.233931",
     "exception": false,
     "start_time": "2022-04-20T12:16:16.493050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aptos2019-blindness-detection', 'densenet121weights']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e19942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T12:16:21.259070Z",
     "iopub.status.busy": "2022-04-20T12:16:21.258511Z",
     "iopub.status.idle": "2022-04-20T12:16:21.722932Z",
     "shell.execute_reply": "2022-04-20T12:16:21.722221Z"
    },
    "papermill": {
     "duration": 0.478393,
     "end_time": "2022-04-20T12:16:21.724974",
     "exception": false,
     "start_time": "2022-04-20T12:16:21.246581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Image Libs.\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D, Flatten, Dense, GaussianDropout, BatchNormalization, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras import regularizers, optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.applications.densenet import DenseNet121\n",
    "\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b09552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T12:16:21.749365Z",
     "iopub.status.busy": "2022-04-20T12:16:21.749142Z",
     "iopub.status.idle": "2022-04-20T12:16:21.772042Z",
     "shell.execute_reply": "2022-04-20T12:16:21.771416Z"
    },
    "papermill": {
     "duration": 0.037439,
     "end_time": "2022-04-20T12:16:21.773731",
     "exception": false,
     "start_time": "2022-04-20T12:16:21.736292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n",
    "train_df['diagnosis'] = train_df['diagnosis'].astype('str')\n",
    "train_df['id_code'] = train_df['id_code'].astype(str)+'.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bdc1fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T12:16:21.797732Z",
     "iopub.status.busy": "2022-04-20T12:16:21.797526Z",
     "iopub.status.idle": "2022-04-20T12:16:21.810399Z",
     "shell.execute_reply": "2022-04-20T12:16:21.809788Z"
    },
    "papermill": {
     "duration": 0.026417,
     "end_time": "2022-04-20T12:16:21.812001",
     "exception": false,
     "start_time": "2022-04-20T12:16:21.785584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE=224\n",
    "\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    #         print(img1.shape,img2.shape,img3.shape)\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    #         print(img.shape)\n",
    "        return img\n",
    "\n",
    "def circle_crop(img, sigmaX = 30):   \n",
    "    \"\"\"\n",
    "    Create circular crop around image centre    \n",
    "    \"\"\"    \n",
    "    img = crop_image_from_gray(img)    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    height, width, depth = img.shape    \n",
    "    \n",
    "    x = int(width/2)\n",
    "    y = int(height/2)\n",
    "    r = np.amin((x,y))\n",
    "    \n",
    "    circle_img = np.zeros((height, width), np.uint8)\n",
    "    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n",
    "    img = cv2.bitwise_and(img, img, mask=circle_img)\n",
    "    img = crop_image_from_gray(img)\n",
    "    img=cv2.addWeighted(img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n",
    "    return img \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(img):\n",
    "    img = circle_crop(img) \n",
    "    img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fcb7ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T12:16:21.835400Z",
     "iopub.status.busy": "2022-04-20T12:16:21.834871Z",
     "iopub.status.idle": "2022-04-20T12:16:29.176145Z",
     "shell.execute_reply": "2022-04-20T12:16:29.175026Z"
    },
    "papermill": {
     "duration": 7.355034,
     "end_time": "2022-04-20T12:16:29.178056",
     "exception": false,
     "start_time": "2022-04-20T12:16:21.823022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:337: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2930 validated image filenames belonging to 5 classes.\n",
      "Found 732 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    validation_split=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zca_whitening = True)\n",
    "\n",
    "batch_size = 16\n",
    "image_size = 224\n",
    "\n",
    "train_gen=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"../input/aptos2019-blindness-detection/train_images\",\n",
    "    x_col=\"id_code\",\n",
    "    y_col=\"diagnosis\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(image_size,image_size),\n",
    "    subset='training')\n",
    "\n",
    "test_gen=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"../input/aptos2019-blindness-detection/train_images\",\n",
    "    x_col=\"id_code\",\n",
    "    y_col=\"diagnosis\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\", \n",
    "    target_size=(image_size,image_size),\n",
    "    subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd42eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T12:16:29.203487Z",
     "iopub.status.busy": "2022-04-20T12:16:29.203167Z",
     "iopub.status.idle": "2022-04-20T12:16:29.208141Z",
     "shell.execute_reply": "2022-04-20T12:16:29.207411Z"
    },
    "papermill": {
     "duration": 0.019599,
     "end_time": "2022-04-20T12:16:29.209843",
     "exception": false,
     "start_time": "2022-04-20T12:16:29.190244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = train_df['diagnosis']\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec874a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T12:16:29.237900Z",
     "iopub.status.busy": "2022-04-20T12:16:29.237291Z",
     "iopub.status.idle": "2022-04-20T12:16:35.011137Z",
     "shell.execute_reply": "2022-04-20T12:16:35.010396Z"
    },
    "papermill": {
     "duration": 5.790852,
     "end_time": "2022-04-20T12:16:35.013279",
     "exception": false,
     "start_time": "2022-04-20T12:16:29.222427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 12:16:29.350193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 12:16:29.454690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 12:16:29.455575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 12:16:29.457618: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-20 12:16:29.457990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 12:16:29.458965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 12:16:29.459878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 12:16:31.251815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 12:16:31.252677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 12:16:31.253364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 12:16:31.254596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_model():\n",
    "    dense_121 = DenseNet121(weights='../input/densenet121weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False)\n",
    "    x = dense_121.get_layer('conv5_block16_2_conv').output\n",
    "    x = Conv2D(32, (3, 3), input_shape=[96,96,3], activation='relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    # and a logistic layer -- let's say we have 5 classes\n",
    "    predictions = Dense(5, activation='softmax')(x)\n",
    "    model = Model(inputs=dense_121.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "model=create_model()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001, amsgrad=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de9865da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T12:16:35.041178Z",
     "iopub.status.busy": "2022-04-20T12:16:35.040938Z",
     "iopub.status.idle": "2022-04-20T12:25:35.339164Z",
     "shell.execute_reply": "2022-04-20T12:25:35.338060Z"
    },
    "papermill": {
     "duration": 540.31489,
     "end_time": "2022-04-20T12:25:35.341412",
     "exception": false,
     "start_time": "2022-04-20T12:16:35.026522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:739: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "2022-04-20 12:16:37.514091: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 12:16:46.701195: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 288s 1s/step - loss: 0.9862\n",
      "Epoch 2/2\n",
      "184/184 [==============================] - 249s 1s/step - loss: 0.7958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb1b41c14d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warm up model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i in range(-5,0):\n",
    "    model.layers[i].trainable = True\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(1e-3))\n",
    "\n",
    "model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=(len(train_gen)),\n",
    "    epochs=2,\n",
    "    workers=2, \n",
    "    use_multiprocessing=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a4cc54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T12:25:35.668229Z",
     "iopub.status.busy": "2022-04-20T12:25:35.667912Z",
     "iopub.status.idle": "2022-04-20T12:25:35.688684Z",
     "shell.execute_reply": "2022-04-20T12:25:35.687880Z"
    },
    "papermill": {
     "duration": 0.164047,
     "end_time": "2022-04-20T12:25:35.690596",
     "exception": false,
     "start_time": "2022-04-20T12:25:35.526549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a77cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T12:25:35.977792Z",
     "iopub.status.busy": "2022-04-20T12:25:35.977031Z",
     "iopub.status.idle": "2022-04-20T12:25:35.983245Z",
     "shell.execute_reply": "2022-04-20T12:25:35.982440Z"
    },
    "papermill": {
     "duration": 0.151801,
     "end_time": "2022-04-20T12:25:35.985131",
     "exception": false,
     "start_time": "2022-04-20T12:25:35.833330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "early= EarlyStopping(monitor='val_loss', mode ='min', verbose = 1, patience = 20)\n",
    "checkpoint = ModelCheckpoint('../working/dr-densenet121.h5', monitor='val_loss', save_best_only = False, mode ='min', verbose = 1)\n",
    "csv_logger = CSVLogger(filename='../working/training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "callbacks_list=[early,checkpoint,csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "373b118e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T12:25:36.273366Z",
     "iopub.status.busy": "2022-04-20T12:25:36.272575Z",
     "iopub.status.idle": "2022-04-20T15:28:24.884919Z",
     "shell.execute_reply": "2022-04-20T15:28:24.883979Z"
    },
    "papermill": {
     "duration": 10968.912629,
     "end_time": "2022-04-20T15:28:25.041198",
     "exception": false,
     "start_time": "2022-04-20T12:25:36.128569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "184/184 [==============================] - 463s 2s/step - loss: 0.7353 - accuracy: 0.7259 - val_loss: 0.7143 - val_accuracy: 0.7309\n",
      "\n",
      "Epoch 00001: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 2/25\n",
      "184/184 [==============================] - 436s 2s/step - loss: 0.5706 - accuracy: 0.7645 - val_loss: 0.5818 - val_accuracy: 0.7582\n",
      "\n",
      "Epoch 00002: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 3/25\n",
      "184/184 [==============================] - 428s 2s/step - loss: 0.5112 - accuracy: 0.7863 - val_loss: 0.6117 - val_accuracy: 0.7637\n",
      "\n",
      "Epoch 00003: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 4/25\n",
      "184/184 [==============================] - 427s 2s/step - loss: 0.4881 - accuracy: 0.8078 - val_loss: 0.5616 - val_accuracy: 0.8046\n",
      "\n",
      "Epoch 00004: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 5/25\n",
      "184/184 [==============================] - 420s 2s/step - loss: 0.4351 - accuracy: 0.8276 - val_loss: 0.5788 - val_accuracy: 0.7650\n",
      "\n",
      "Epoch 00005: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 6/25\n",
      "184/184 [==============================] - 418s 2s/step - loss: 0.4048 - accuracy: 0.8410 - val_loss: 0.4953 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00006: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 7/25\n",
      "184/184 [==============================] - 420s 2s/step - loss: 0.3549 - accuracy: 0.8679 - val_loss: 0.5850 - val_accuracy: 0.8005\n",
      "\n",
      "Epoch 00007: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 8/25\n",
      "184/184 [==============================] - 467s 3s/step - loss: 0.3415 - accuracy: 0.8710 - val_loss: 0.6794 - val_accuracy: 0.7760\n",
      "\n",
      "Epoch 00008: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 9/25\n",
      "184/184 [==============================] - 418s 2s/step - loss: 0.3298 - accuracy: 0.8788 - val_loss: 0.7014 - val_accuracy: 0.7705\n",
      "\n",
      "Epoch 00009: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 10/25\n",
      "184/184 [==============================] - 420s 2s/step - loss: 0.2982 - accuracy: 0.8894 - val_loss: 0.5739 - val_accuracy: 0.8060\n",
      "\n",
      "Epoch 00010: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 11/25\n",
      "184/184 [==============================] - 421s 2s/step - loss: 0.2852 - accuracy: 0.8918 - val_loss: 0.5608 - val_accuracy: 0.8142\n",
      "\n",
      "Epoch 00011: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 12/25\n",
      "184/184 [==============================] - 421s 2s/step - loss: 0.2464 - accuracy: 0.9092 - val_loss: 0.5638 - val_accuracy: 0.8169\n",
      "\n",
      "Epoch 00012: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 13/25\n",
      "184/184 [==============================] - 424s 2s/step - loss: 0.2321 - accuracy: 0.9137 - val_loss: 0.6360 - val_accuracy: 0.7773\n",
      "\n",
      "Epoch 00013: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 14/25\n",
      "184/184 [==============================] - 426s 2s/step - loss: 0.2150 - accuracy: 0.9191 - val_loss: 0.6097 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00014: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 15/25\n",
      "184/184 [==============================] - 435s 2s/step - loss: 0.2009 - accuracy: 0.9201 - val_loss: 0.6869 - val_accuracy: 0.8019\n",
      "\n",
      "Epoch 00015: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 16/25\n",
      "184/184 [==============================] - 442s 2s/step - loss: 0.1761 - accuracy: 0.9369 - val_loss: 0.7889 - val_accuracy: 0.8087\n",
      "\n",
      "Epoch 00016: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 17/25\n",
      "184/184 [==============================] - 432s 2s/step - loss: 0.1524 - accuracy: 0.9495 - val_loss: 0.7032 - val_accuracy: 0.8033\n",
      "\n",
      "Epoch 00017: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 18/25\n",
      "184/184 [==============================] - 435s 2s/step - loss: 0.1356 - accuracy: 0.9526 - val_loss: 0.7991 - val_accuracy: 0.7910\n",
      "\n",
      "Epoch 00018: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 19/25\n",
      "184/184 [==============================] - 433s 2s/step - loss: 0.1336 - accuracy: 0.9529 - val_loss: 0.7998 - val_accuracy: 0.7869\n",
      "\n",
      "Epoch 00019: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 20/25\n",
      "184/184 [==============================] - 434s 2s/step - loss: 0.1163 - accuracy: 0.9611 - val_loss: 0.8715 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00020: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 21/25\n",
      "184/184 [==============================] - 431s 2s/step - loss: 0.1169 - accuracy: 0.9614 - val_loss: 0.7230 - val_accuracy: 0.7842\n",
      "\n",
      "Epoch 00021: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 22/25\n",
      "184/184 [==============================] - 478s 3s/step - loss: 0.0852 - accuracy: 0.9683 - val_loss: 0.9020 - val_accuracy: 0.8101\n",
      "\n",
      "Epoch 00022: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 23/25\n",
      "184/184 [==============================] - 435s 2s/step - loss: 0.1113 - accuracy: 0.9659 - val_loss: 0.7779 - val_accuracy: 0.7732\n",
      "\n",
      "Epoch 00023: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 24/25\n",
      "184/184 [==============================] - 478s 3s/step - loss: 0.0779 - accuracy: 0.9730 - val_loss: 0.9078 - val_accuracy: 0.7978\n",
      "\n",
      "Epoch 00024: saving model to ../working/dr-densenet121.h5\n",
      "Epoch 25/25\n",
      "184/184 [==============================] - 432s 2s/step - loss: 0.0922 - accuracy: 0.9672 - val_loss: 0.7919 - val_accuracy: 0.7964\n",
      "\n",
      "Epoch 00025: saving model to ../working/dr-densenet121.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb123f86b50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=Adam(learning_rate=1e-4, amsgrad=True), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train_gen,              \n",
    "                                    steps_per_epoch=len(train_gen),\n",
    "                                    validation_data=test_gen,                    \n",
    "                                    validation_steps=len(test_gen),\n",
    "                                    epochs=25,\n",
    "                                    callbacks = callbacks_list, \n",
    "                                    use_multiprocessing = True,\n",
    "                                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce9f0a",
   "metadata": {
    "papermill": {
     "duration": 1.865875,
     "end_time": "2022-04-20T15:28:28.520171",
     "exception": false,
     "start_time": "2022-04-20T15:28:26.654296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11544.584257,
   "end_time": "2022-04-20T15:28:33.085216",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-20T12:16:08.500959",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
