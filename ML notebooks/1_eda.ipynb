{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Business Problem and Use of Deep Learning](#section1)<br>\n",
    "[2. Visualization of Images](#section2)<br>\n",
    "[3. Image Processing](#section3)<br>\n",
    "[4. TSNE Visualization](#section4)<br>\n",
    "[5. Data Augmentation](#section5)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref - https://stackoverflow.com/questions/14463277/how-to-disable-python-warnings\n",
    "# dataset =https://www.kaggle.com/c/aptos2019-blindness-detection\n",
    "# Basic Libs..\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from prettytable import PrettyTable\n",
    "import pickle\n",
    "import os\n",
    "print('CWD is ',os.getcwd())\n",
    "\n",
    "# Vis Libs..\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "# Image Libs.\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# DL Libs..\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array,array_to_img,load_img\n",
    "from keras import optimizers,Model,Sequential\n",
    "from keras.layers import Input,GlobalAveragePooling2D,Dropout,Dense,Activation\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a id = 'section1'> <font color='red'>  1. Business Problem and Use of Deep Learning</font> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> 1.1 Business Problem Description </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This case study is based on a Kaggle Competition conducted 7 months back based on a dataset by Aravind Eye Hospital in India to detect a form of Blindness called Diabetic Retinopathy. https://www.kaggle.com/c/aptos2019-blindness-detection/overview is the link to the Kaggle competition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> 1.2 Use of Deep Learning </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The goal here is to Build an Image Classification Model which can take a look at the images and classify the image into one of the 5 classes (0,1,2,3,4). This Image Classification Model can accelerate the process of Blindness Detection in Patients. Currently Doctors review the Image and classify it into one of the classes - \n",
    "\n",
    "##### 0 - No DR\n",
    "##### 1 - Mild\n",
    "##### 2 - Moderate\n",
    "##### 3 - Severe\n",
    "##### 4 - Proliferative DR\n",
    "\n",
    "##### Training data contains 3662 images, test data contains 1928 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> 1.3 Evaluation Metric </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The evaluation metric used is Quadratic Weighted Kappa score - https://www.kaggle.com/c/aptos2019-blindness-detection/overview/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref - https://stackoverflow.com/questions/10628262/inserting-image-into-ipython-notebook-markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"eval_metric_img.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a id = 'section2'> <font color='red'>  2. Visualization of Images</font> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function reads data from the respective train and test directories\n",
    "'''\n",
    "\n",
    "def load_data():\n",
    "    train = pd.read_csv('train.csv')\n",
    "    test = pd.read_csv('test.csv')\n",
    "    \n",
    "    train_dir = os.path.join('./','train_images/')\n",
    "    test_dir = os.path.join('./','test_images/')\n",
    "    \n",
    "    train['file_path'] = train['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\n",
    "    test['file_path'] = test['id_code'].map(lambda x: os.path.join(test_dir,'{}.png'.format(x)))\n",
    "    \n",
    "    train['file_name'] = train[\"id_code\"].apply(lambda x: x + \".png\")\n",
    "    test['file_name'] = test[\"id_code\"].apply(lambda x: x + \".png\")\n",
    "    \n",
    "    train['diagnosis'] = train['diagnosis'].astype(str)\n",
    "    \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = load_data()\n",
    "print(df_train.shape,df_test.shape,'\\n')\n",
    "df_train.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> 2.1 Class Distribution </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This Function Plots a Bar plot of output Classes Distribution'''\n",
    "\n",
    "def plot_classes(df):\n",
    "    df_group = pd.DataFrame(df.groupby('diagnosis').agg('size').reset_index())\n",
    "    df_group.columns = ['diagnosis','count']\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(10,5)}, style = 'whitegrid')\n",
    "    sns.barplot(x = 'diagnosis',y='count',data = df_group,palette = \"Blues_d\")\n",
    "    plt.title('Output Class Distribution')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Summary - As we can see, there is class imbalance in the output class distribution. We shall account for this while training the models using data augmentation / class balancing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> 2.2 Visualize Images </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a global variable to be used as Image size..\n",
    "IMG_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This Function converts a color image to gray scale image'''\n",
    "\n",
    "def conv_gray(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "    return img\n",
    "  \n",
    "    \n",
    "'''\n",
    "This Function shows the visual Image photo of 'n x 5' points (5 of each class)\n",
    "'''\n",
    "\n",
    "def visualize_imgs(df,pts_per_class,color_scale):\n",
    "    df = df.groupby('diagnosis',group_keys = False).apply(lambda df: df.sample(pts_per_class))\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    plt.rcParams[\"axes.grid\"] = False\n",
    "    for pt in range(pts_per_class):\n",
    "        f, axarr = plt.subplots(1,5,figsize = (15,15))\n",
    "        axarr[0].set_ylabel(\"Sample Data Points\")\n",
    "        \n",
    "        df_temp = df[df.index.isin([pt + (pts_per_class*0),pt + (pts_per_class*1), pt + (pts_per_class*2),pt + (pts_per_class*3),pt + (pts_per_class*4)])]\n",
    "        for i in range(5):\n",
    "            if color_scale == 'gray':\n",
    "                img = conv_gray(cv2.imread(df_temp.file_path.iloc[i]))\n",
    "                axarr[i].imshow(img,cmap = color_scale)\n",
    "            else:\n",
    "                axarr[i].imshow(Image.open(df_temp.file_path.iloc[i]).resize((IMG_SIZE,IMG_SIZE)))\n",
    "            axarr[i].set_xlabel('Class '+str(df_temp.diagnosis.iloc[i]))\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_imgs(df_train,3,color_scale = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_imgs(df_train,2,color_scale = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot summary - As we can see, as we move towards higher classes, we are able to comprehend larger number of abnormalities in the eye images. Also, the lightning and brightness conditions are not even across all images. We will try to handle this using image processing techniques. Also, Gray Scale Images are giving better visualization of the eye features as compared to RGB images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ref - https://www.kaggle.com/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy\n",
    "##### This below photo shows what the eye diabetic retinopathy condition refers to using the reference link from the above kaggle kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sample_eye_img.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a id = 'section3'> <font color='red'>  3. Image Processing</font> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> 3.1 Gaussian Blur </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference - https://www.kaggle.com/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy#3.-Further-improve-by-auto-cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This section of code applies gaussian blur on top of image\n",
    "'''\n",
    "\n",
    "rn = np.random.randint(low = 0,high = len(df_train) - 1)\n",
    "\n",
    "img = cv2.imread(df_train.file_path.iloc[rn])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "\n",
    "img_t = cv2.addWeighted(img,4, cv2.GaussianBlur(img , (0,0) , 30) ,-4 ,128)\n",
    "\n",
    "f, axarr = plt.subplots(1,2,figsize = (11,11))\n",
    "axarr[0].imshow(img)\n",
    "axarr[1].imshow(img_t)\n",
    "plt.title('After applying Gaussian Blur')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot summary - As we can see, after applying Gaussian Blur, We are able to bring out the features/image details much more clearer in the eye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> 3.2 Gaussian Blur with Circular Cropping </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This Function performs image processing on top of images by performing Gaussian Blur and Circle Crop\n",
    "'''\n",
    "\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    #         print(img1.shape,img2.shape,img3.shape)\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    #         print(img.shape)\n",
    "        return img\n",
    "    \n",
    "    \n",
    "def circle_crop(img, sigmaX):   \n",
    "    \"\"\"\n",
    "    Create circular crop around image centre    \n",
    "    \"\"\"    \n",
    "    img = crop_image_from_gray(img)    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    height, width, depth = img.shape    \n",
    "    \n",
    "    x = int(width/2)\n",
    "    y = int(height/2)\n",
    "    r = np.amin((x,y))\n",
    "    \n",
    "    circle_img = np.zeros((height, width), np.uint8)\n",
    "    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n",
    "    img = cv2.bitwise_and(img, img, mask=circle_img)\n",
    "    img = crop_image_from_gray(img)\n",
    "    img=cv2.addWeighted(img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Perform Image Processing on a sample image'''\n",
    "\n",
    "rn = np.random.randint(low = 0,high = len(df_train) - 1)\n",
    "\n",
    "#img = img_t\n",
    "img = cv2.imread(df_train.file_path.iloc[rn])\n",
    "img_t = circle_crop(img,sigmaX = 30)\n",
    "\n",
    "f, axarr = plt.subplots(1,2,figsize = (11,11))\n",
    "axarr[0].imshow(cv2.resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB),(IMG_SIZE,IMG_SIZE)))\n",
    "axarr[1].imshow(img_t)\n",
    "plt.title('After applying Circular Crop and Gaussian Blur')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot summary - As we can see above, now the image features and details are very much clearer than what the image was before, we are ready to use this image for modelling as the image details are much more clearer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref - https://www.kaggle.com/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy\n",
    "'''\n",
    "This Function shows the visual Image photo of 'n x 5' points (5 of each class) \n",
    "and performs image processing (Gaussian Blur, Circular crop) transformation on top of that\n",
    "'''\n",
    "\n",
    "def visualize_img_process(df,pts_per_class,sigmaX):\n",
    "    df = df.groupby('diagnosis',group_keys = False).apply(lambda df: df.sample(pts_per_class))\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    plt.rcParams[\"axes.grid\"] = False\n",
    "    for pt in range(pts_per_class):\n",
    "        f, axarr = plt.subplots(1,5,figsize = (15,15))\n",
    "        axarr[0].set_ylabel(\"Sample Data Points\")\n",
    "        \n",
    "        df_temp = df[df.index.isin([pt + (pts_per_class*0),pt + (pts_per_class*1), pt + (pts_per_class*2),pt + (pts_per_class*3),pt + (pts_per_class*4)])]\n",
    "        for i in range(5):\n",
    "            img = cv2.imread(df_temp.file_path.iloc[i])\n",
    "            img = circle_crop(img,sigmaX)\n",
    "            axarr[i].imshow(img)\n",
    "            axarr[i].set_xlabel('Class '+str(df_temp.diagnosis.iloc[i]))\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_img_process(df_train,5,sigmaX = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizations Summary - Clearly we understand the importance of performing image processing operations here. We have performed Gaussian Blur to bring out the image details and features much more clearly and explicitly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a id = 'section4'> <font color='red'>  4. TSNE Visualization</font> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code below applies TSNE on Gray Scale Images - The Image is flattened to 2D Gray Image to 1D and then applies TSNE\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref - https://www.kaggle.com/code1110/are-there-clusters-pca-tsne-vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train image data\n",
    "npix = 224 # resize to npix x npix (for now)\n",
    "X_train = np.zeros((df_train.shape[0], npix, npix))\n",
    "for i in tqdm_notebook(range(df_train.shape[0])):\n",
    "    # load an image\n",
    "    img = cv2.imread(df_train.file_path.iloc[i])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    X_train[i, :, :] = cv2.resize(img, (npix, npix)) \n",
    "    \n",
    "print(\"X_train shape: \" + str(np.shape(X_train)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "X = X_train / 255\n",
    "\n",
    "# reshape\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "trainy = df_train['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "per_vals = [2,5,10,15,20,30,40,50]\n",
    "\n",
    "for per in tqdm_notebook(per_vals):\n",
    "    X_decomposed = TSNE(n_components=2,perplexity = per).fit_transform(X)\n",
    "    df_tsne = pd.DataFrame(data=X_decomposed, columns=['Dimension_x','Dimension_y'])\n",
    "    df_tsne['Score'] = trainy.values\n",
    "    \n",
    "    sns.FacetGrid(df_tsne, hue='Score', size=6).map(plt.scatter, 'Dimension_x', 'Dimension_y').add_legend()\n",
    "    plt.title('TSNE for perplexity = ' + str(per))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot summary - As we can see, we are able to seperate Class '0' from other classes (1-4). Seperating between classes 1-4 looks challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a id = 'section5'> <font color='red'>  5. Data Augmentation</font> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref - https://www.youtube.com/watch?v=hxLU32zhze0\n",
    "# ref - https://stackoverflow.com/questions/49643907/clipping-input-data-to-the-valid-range-for-imshow-with-rgb-data-0-1-for-floa\n",
    "# ref - https://keras.io/preprocessing/image/\n",
    "\n",
    "'''This Function generates 'lim' number of Image Augmentations from a random Image in the directory'''\n",
    "\n",
    "def generate_augmentations(lim):\n",
    "    datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                                 featurewise_std_normalization=True,\n",
    "                                 rotation_range=20,\n",
    "                                 #width_shift_range=0.2,\n",
    "                                 #height_shift_range=0.2,\n",
    "                                 horizontal_flip=True)\n",
    "    img = cv2.imread(df_train.file_path.iloc[np.random.randint(low = 0,high = len(df_train) - 1)])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "    plt.imshow(img)\n",
    "    plt.title('ORIGINAL IMAGE')\n",
    "    plt.show()\n",
    "    \n",
    "    img_arr = img.reshape((1,) + img.shape)\n",
    "    \n",
    "    i = 0\n",
    "    for img_iterator in datagen.flow(x = img_arr,batch_size = 1):\n",
    "        i = i + 1\n",
    "        if i > lim:\n",
    "            break\n",
    "        plt.imshow((img_iterator.reshape(img_arr[0].shape)).astype(np.uint8))\n",
    "        plt.title('IMAGE AUGMENTATION ' + str(i))\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_augmentations(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Summary - As we can see above, Image Augmentations are extremely helpful for this datasets to make our Models more Robust and would also have a higher ability to generalize well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}